{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "Uk6WXj27hCP5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqgHpDdIfi5Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define path/directory"
      ],
      "metadata": {
        "id": "QG2G5ee-g83P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_path = './baju_adat'\n",
        "\n",
        "source_path_madura = os.path.join(source_path, 'madura')\n",
        "source_path_asmat = os.path.join(source_path, 'asmat')\n",
        "source_path_dayak = os.path.join(source_path, 'dayak')\n",
        "source_path_minang = os.path.join(source_path, 'minang')\n",
        "source_path_bali = os.path.join(source_path, 'bali')\n",
        "source_path_bugis = os.path.join(source_path, 'bugis')\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_madura))} images of Madura.\")\n",
        "print(f\"There are {len(os.listdir(source_path_asmat))} images of Asmat.\")\n",
        "print(f\"There are {len(os.listdir(source_path_asmat))} images of Dayak.\")\n",
        "print(f\"There are {len(os.listdir(source_path_asmat))} images of Minang.\")\n",
        "print(f\"There are {len(os.listdir(source_path_asmat))} images of Bali.\")\n",
        "print(f\"There are {len(os.listdir(source_path_asmat))} images of Bugis.\")"
      ],
      "metadata": {
        "id": "57om8vGPfpeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define root directory\n",
        "root_dir = '/baju_adat_preprocess'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)"
      ],
      "metadata": {
        "id": "SwSoVOu6fvS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTION: create_train_val_dirs\n",
        "def create_train_val_test_dirs(root_path, list_suku):\n",
        "  \"\"\"\n",
        "  Creates directories for the train and test sets\n",
        "  \n",
        "  Args:\n",
        "    root_path (string) - the base directory path to create subdirectories from\n",
        "  \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # HINT:\n",
        "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
        "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
        "\n",
        "  for suku in list_suku:\n",
        "    os.makedirs(os.path.join(root_path, f'training/{suku}'))\n",
        "    os.makedirs(os.path.join(root_path, f'validation/{suku}'))\n",
        "    os.makedirs(os.path.join(root_path, f'testing/{suku}'))\n",
        "  \n",
        "  ### END CODE HERE"
      ],
      "metadata": {
        "id": "0-YxYUDDo8jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  create_train_val_test_dirs(root_path=root_dir, \n",
        "                             list_suku=['madura','asmat','dayak','minang','bali','bugis'])\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ],
      "metadata": {
        "id": "n5oAVEYZlKYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the created directories as the result of create_train_val_test_dirs function\n",
        "\n",
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ],
      "metadata": {
        "id": "pGiBPkp3gYd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data"
      ],
      "metadata": {
        "id": "QinPqj-cg7PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTION: split_data\n",
        "def split_train_val_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "  \"\"\"\n",
        "  Splits the data into train and test sets\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    TRAINING_DIR (string): directory path to be used for training\n",
        "    VALIDATION_DIR (string): directory path to be used for validation\n",
        "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "  list_file = os.listdir(SOURCE_DIR)\n",
        "  list_file_notzero = []\n",
        "  for files in list_file:\n",
        "    if os.path.getsize(os.path.join(SOURCE_DIR, files)) == 0:\n",
        "      print(f'{files} is zero so length, so ignoring.')\n",
        "    else:\n",
        "      list_file_notzero.extend([files])\n",
        "  \n",
        "  len_train = int(len(list_file_notzero) * SPLIT_SIZE)\n",
        "  len_validation = int(len(list_file_notzero) - len_train)\n",
        "\n",
        "  train_files = random.sample(list_file_notzero, len_train)\n",
        "  validation_files = random.sample(list_file_notzero, len_validation)\n",
        "\n",
        "  for files in train_files:\n",
        "    copyfile(os.path.join(SOURCE_DIR,files), os.path.join(TRAINING_DIR, files))\n",
        "  for files in validation_files:\n",
        "    copyfile(os.path.join(SOURCE_DIR, files), os.path.join(VALIDATION_DIR, files)) \n",
        "\n",
        "\n",
        "  ### END CODE HERE"
      ],
      "metadata": {
        "id": "nz5IZ3Dmgb96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTION: split_data\n",
        "def split_val_test_data(VALIDATION_DIR, TESTING_DIR, SPLIT_SIZE):\n",
        "  \"\"\"\n",
        "  Splits the data into train and test sets\n",
        "  \n",
        "  Args:\n",
        "    SOURCE_DIR (string): directory path containing the images\n",
        "    TRAINING_DIR (string): directory path to be used for training\n",
        "    VALIDATION_DIR (string): directory path to be used for validation\n",
        "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
        "    \n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "  list_file = os.listdir(VALIDATION_DIR)\n",
        "  list_file_notzero = []\n",
        "  for files in list_file:\n",
        "    if os.path.getsize(os.path.join(VALIDATION_DIR, files)) == 0:\n",
        "      print(f'{files} is zero so length, so ignoring.')\n",
        "    else:\n",
        "      list_file_notzero.extend([files])\n",
        "  \n",
        "  len_validation = int(len(list_file_notzero) * SPLIT_SIZE)\n",
        "  len_testing = int(len(list_file_notzero) - len_validation)\n",
        "\n",
        "  testing_files = random.sample(list_file_notzero, len_testing)\n",
        "\n",
        "  for files in testing_files:\n",
        "    shutil.move(os.path.join(VALIDATION_DIR, files), s.path.join(TESTING_DIR, files))\n",
        "\n",
        "  ### END CODE HERE"
      ],
      "metadata": {
        "id": "vMwDIYpbsH4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your split_data function\n",
        "\n",
        "# Define paths\n",
        "MADURA_SOURCE_DIR = source_path_madura\n",
        "ASMAT_SOURCE_DIR = source_path_asmat\n",
        "DAYAK_SOURCE_DIR = source_path_dayak\n",
        "MINANG_SOURCE_DIR = source_path_minang\n",
        "BALI_SOURCE_DIR = source_path_bali\n",
        "BUGIS_SOURCE_DIR = source_path_bugis\n",
        "\n",
        "TRAINING_DIR = \"/baju_adat_preprocess/training/\"\n",
        "VALIDATION_DIR = \"/baju_adat_preprocess/validation/\"\n",
        "TESTING_DIR = \"/baju_adat_preprocess/testing/\"\n",
        "\n",
        "TRAINING_MADURA_DIR = os.path.join(TRAINING_DIR, \"madura/\")\n",
        "VALIDATION_MADURA_DIR = os.path.join(VALIDATION_DIR, \"madura/\")\n",
        "TESTING_MADURA_DIR = os.path.join(TESTING_DIR, \"madura/\")\n",
        "\n",
        "TRAINING_ASMAT_DIR = os.path.join(TRAINING_DIR, \"asmat/\")\n",
        "VALIDATION_ASMAT_DIR = os.path.join(VALIDATION_DIR, \"asmat/\")\n",
        "TESTING_ASMAT_DIR = os.path.join(TESTING_DIR, \"asmat/\")\n",
        "\n",
        "TRAINING_DAYAK_DIR = os.path.join(TRAINING_DIR, \"dayak/\")\n",
        "VALIDATION_DAYAK_DIR = os.path.join(VALIDATION_DIR, \"dayak/\")\n",
        "TESTING_DAYAK_DIR = os.path.join(TESTING_DIR, \"dayak/\")\n",
        "\n",
        "TRAINING_MINANG_DIR = os.path.join(TRAINING_DIR, \"minang/\")\n",
        "VALIDATION_MINANG_DIR = os.path.join(VALIDATION_DIR, \"minang/\")\n",
        "TESTING_MINANG_DIR = os.path.join(TESTING_DIR, \"minang/\")\n",
        "\n",
        "TRAINING_BALI_DIR = os.path.join(TRAINING_DIR, \"bali/\")\n",
        "VALIDATION_BALI_DIR = os.path.join(VALIDATION_DIR, \"bali/\")\n",
        "TESTING_BALI_DIR = os.path.join(TESTING_DIR, \"bali/\")\n",
        "\n",
        "TRAINING_BUGIS_DIR = os.path.join(TRAINING_DIR, \"bugis/\")\n",
        "VALIDATION_BUGIS_DIR = os.path.join(VALIDATION_DIR, \"bugis/\")\n",
        "TESTING_BUGIS_DIR = os.path.join(TESTING_DIR, \"bugis/\")"
      ],
      "metadata": {
        "id": "vRsNgy2IgjRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(TRAINING_MADURA_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_MADURA_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_ASMAT_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_ASMAT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_DAYAK_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_DAYAK_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_MINANG_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_MINANG_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_BALI_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_BALI_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_BUGIS_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_BUGIS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "if len(os.listdir(VALIDATION_MADURA_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_MADURA_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_ASMAT_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_ASMAT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_DAYAK_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_DAYAK_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_MINANG_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_MINANG_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_BALI_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_BALI_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_BUGIS_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_BUGIS_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "if len(os.listdir(TESTING_MADURA_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_MADURA_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_ASMAT_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_ASMAT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_DAYAK_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_DAYAK_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_MINANG_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_MINANG_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_BALI_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_BALI_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_BUGIS_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_BUGIS_DIR):\n",
        "    os.remove(file.path)"
      ],
      "metadata": {
        "id": "70iOv8RvtUp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define proportion of images used for training\n",
        "# Train:val:test = 90% : 5% : 5%\n",
        "train_val_split_size = .9\n",
        "val_test_split_size = .5\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_train_val_data(MADURA_SOURCE_DIR, TRAINING_MADURA_DIR, VALIDATION_MADURA_DIR, train_val_split_size) # train val split \n",
        "split_val_test_data(VALIDATION_MADURA_DIR, TESTING_MADURA_DIR, val_test_split_size) # val test split\n",
        "\n",
        "split_train_val_data(ASMAT_SOURCE_DIR, TRAINING_ASMAT_DIR, VALIDATION_ASMAT_DIR, train_val_split_size) # train val split \n",
        "split_val_test_data(VALIDATION_ASMAT_DIR, TESTING_ASMAT_DIR, val_test_split_size) # val test split\n",
        "\n",
        "split_train_val_data(DAYAK_SOURCE_DIR, TRAINING_DAYAK_DIR, VALIDATION_DAYAK_DIR, train_val_split_size) # train val split \n",
        "split_val_test_data(VALIDATION_DAYAK_DIR, TESTING_DAYAK_DIR, val_test_split_size) # val test split\n",
        "\n",
        "split_train_val_data(MINANG_SOURCE_DIR, TRAINING_MINANG_DIR, VALIDATION_MINANG_DIR, train_val_split_size) # train val split \n",
        "split_val_test_data(VALIDATION_MINANG_DIR, TESTING_MINANG_DIR, val_test_split_size) # val test split\n",
        "\n",
        "split_train_val_data(BALI_SOURCE_DIR, TRAINING_BALI_DIR, VALIDATION_BALI_DIR, train_val_split_size) # train val split \n",
        "split_val_test_data(VALIDATION_BALI_DIR, TESTING_BALI_DIR, val_test_split_size) # val test split\n",
        "\n",
        "split_train_val_data(BUGIS_SOURCE_DIR, TRAINING_BUGIS_DIR, VALIDATION_BUGIS_DIR, train_val_split_size) # train val split \n",
        "split_val_test_data(VALIDATION_BUGIS_DIR, TESTING_BUGIS_DIR, val_test_split_size) # val test split"
      ],
      "metadata": {
        "id": "t97Q7nqsrIsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
        "print(f\"\\n\\nOriginal Madura's directory has {len(os.listdir(MADURA_SOURCE_DIR))} images\")\n",
        "print(f\"Original Asmat's directory has {len(os.listdir(ASMAT_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Original Dayak's directory has {len(os.listdir(DAYAK_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Original Minang's directory has {len(os.listdir(MINANG_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Original Bali's directory has {len(os.listdir(BALI_SOURCE_DIR))} images\\n\")\n",
        "print(f\"Original Bugis's directory has {len(os.listdir(BUGIS_SOURCE_DIR))} images\\n\")\n",
        "\n",
        "# Training and validation splits. Check that the number of images matches the expected output.\n",
        "print(f\"There are {len(os.listdir(TRAINING_MADURA_DIR))} images of Madura for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_ASMAT_DIR))} images of Asmat for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_DAYAK_DIR))} images of Dayak for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_MINANG_DIR))} images of Minang for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_BALI_DIR))} images of Bali for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_BUGIS_DIR))} images of Bugis for training\")\n",
        "print()\n",
        "print(f\"There are {len(os.listdir(VALIDATION_MADURA_DIR))} images of Madura for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_ASMAT_DIR))} images of Asmat for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_DAYAK_DIR))} images of Dayak for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_MINANG_DIR))} images of Minang for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_BALI_DIR))} images of Bali for validation\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_BUGIS_DIR))} images of Bugis for validation\")\n",
        "print()\n",
        "print(f\"There are {len(os.listdir(TESTING_MADURA_DIR))} images of Madura for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_ASMAT_DIR))} images of Asmat for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_DAYAK_DIR))} images of Dayak for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_MINANG_DIR))} images of Minang for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_BALI_DIR))} images of Bali for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_BUGIS_DIR))} images of Bugis for testing\")"
      ],
      "metadata": {
        "id": "1V0yFDtqrJ4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train_val generators incl. image augmentation"
      ],
      "metadata": {
        "id": "2fcCuLWgg2fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_test_generators(TRAINING_DIR, VALIDATION_DIR, TESTING_DIR):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "  \n",
        "  Args:\n",
        "    TRAINING_DIR (string): directory path containing the training images\n",
        "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
        "    \n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                                     rotation_range=50,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=20,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=20,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(150, 150))\n",
        "\n",
        "\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  test_generator = test_datagen.flow_from_directory(directory=TESTING_DIR,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator, test_generator"
      ],
      "metadata": {
        "id": "2n9MaI37gmnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your generators\n",
        "train_generator, validation_generator, test_generator = train_val_test_generators(TRAINING_DIR, VALIDATION_DIR, TESTING_DIR)"
      ],
      "metadata": {
        "id": "A9SHNJZYg0s9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}